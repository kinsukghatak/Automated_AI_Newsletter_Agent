{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":121144,"databundleVersionId":14484960,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Automated Weekly AI Newsletter agent :\n\nThis notebook showcases a sophisticated, end-to-end multi-agent system built using the Google Agent Development Kit (ADK) to automatically research, coordinate, and generate a professional weekly newsletter on Artificial Intelligence and Machine Learning. The system demonstrates advanced agentic capabilities, tool use, and complex sequential orchestration.\n\n**Key Features and Capabilities**\n**Four Specialized Agents:** The system is composed of four dedicated research agents and one final formatting agent, each equipped with specific tools and instructions for highly focused data collection.\n\n**Diverse Tool Integration:** Integrates the official Google Search tool, a custom Python function for the YouTube API, a custom Python function for the ArXiv API, and the MCP Toolset for GitHub data extraction.\n\n**Sequential Orchestration:** A SequentialAgent acts as the RootOrchestrator, managing the flow from data gathering to final content generation.","metadata":{}},{"cell_type":"code","source":"# pip install google-adk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T20:25:45.641861Z","iopub.execute_input":"2025-11-16T20:25:45.642075Z","iopub.status.idle":"2025-11-16T20:25:53.547305Z","shell.execute_reply.started":"2025-11-16T20:25:45.642056Z","shell.execute_reply":"2025-11-16T20:25:53.546058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"âœ… Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )\n\ntry:\n    youtube_api_key = UserSecretsClient().get_secret(\"youtube_api_key\")\n    os.environ[\"youtube_api_key\"] = youtube_api_key\n    print(\"âœ… youtube_api_key  key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"ðŸ”‘ Authentication Error: Please make sure you have added 'youtube_api_key' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:12:36.184125Z","iopub.execute_input":"2025-11-28T23:12:36.184441Z","iopub.status.idle":"2025-11-28T23:12:36.326608Z","shell.execute_reply.started":"2025-11-28T23:12:36.184355Z","shell.execute_reply":"2025-11-28T23:12:36.325423Z"}},"outputs":[{"name":"stdout","text":"âœ… Gemini API key setup complete.\nâœ… youtube_api_key  key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import required libraries\n\nfrom google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nimport asyncio\nfrom google.adk.agents import Agent\nfrom google.adk.tools.mcp_tool import MCPToolset\nfrom google.genai import types\nfrom mcp.client.stdio import StdioServerParameters\nfrom datetime import datetime, timedelta\nfrom google.adk.tools.mcp_tool.mcp_toolset import StdioConnectionParams\nimport xml.etree.ElementTree as ET\nimport requests\n\n\n\nprint(\"âœ… ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:12:37.958942Z","iopub.execute_input":"2025-11-28T23:12:37.959218Z","iopub.status.idle":"2025-11-28T23:13:21.257729Z","shell.execute_reply.started":"2025-11-28T23:12:37.959197Z","shell.execute_reply":"2025-11-28T23:13:21.256938Z"}},"outputs":[{"name":"stdout","text":"âœ… ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=15,  # Delay multiplier\n    initial_delay=3,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:13:21.259003Z","iopub.execute_input":"2025-11-28T23:13:21.260194Z","iopub.status.idle":"2025-11-28T23:13:21.265009Z","shell.execute_reply.started":"2025-11-28T23:13:21.260169Z","shell.execute_reply":"2025-11-28T23:13:21.263744Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"#  Sec 1: Design the Subagents for research : ","metadata":{}},{"cell_type":"markdown","source":"### Setion 1.1 :  Design the subagent 1 for Google search of latest AI topics and blogs / articles","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent_google = Agent(\n    name=\"ResearchAgent_google\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"\n    You are a specialized research agent for discovering top AI/ML news articles from \n    the period mentioned by the user.\n\n\n    Your INDEPENDENT task:\n    1. Use the google_search tool to find the most relevant and widely discussed AI/ML news from \n    the specific timeline share by the user\n    2. Execute 4-5 targeted searches to get comprehensive coverage:\n       - \"artificial intelligence news latest\"\n       - \"machine learning breakthrough latest\"\n       - \"AI company announcement recent\"\n       - \"generative AI LLM news\"\n       - \"AI research development 2024 , 2025\"\n    \n    3. From ALL search results, identify the 4-5 MOST SIGNIFICANT news stories\n    \n    4. For EACH story, you MUST extract and include:\n       - Headline/Title of the article\n       - Source/Publication name (e.g., TechCrunch, Reuters, OpenAI Blog)\n       - Brief summary (2-3 sentences) explaining what happened and why it matters\n       - **THE COMPLETE URL** - This is CRITICAL! Always include the full clickable link\n    \n    Selection criteria for top stories:\n    - Breaking news or major announcements\n    - Significant product launches or updates\n    - Important research breakthroughs\n    - Industry-shaping developments\n    - High credibility sources (avoid random blogs)\n    \n    Output format - Use EXACTLY this structure:\n    \n    â€¢ **[Article Headline]** - [Source Name]\n      Summary: [2-3 sentences explaining the news and its significance]\n      ðŸ”— URL: [FULL URL HERE - must be included!]\n]\n    \n    [Continue for all 4-5 stories...]\n    \n    CRITICAL REQUIREMENTS:\n    âœ“ ALWAYS include the complete URL for every article\n    âœ“ Make sure URLs are clickable and complete (start with http:// or https://)\n    âœ“ If a search result doesn't provide a clear URL, skip that result and find another\n    âœ“ Verify each story is from the provided timeline or very recent\n    âœ“ Prioritize authoritative sources (major news outlets, company blogs, research institutions)\n    âœ“ Each summary should explain WHAT happened, WHO is involved, and WHY it matters\n    \n    Example of CORRECT formatting:\n    \n    â€¢ **OpenAI Launches GPT-5 with Breakthrough Reasoning Capabilities** - OpenAI Blog\n      Summary: OpenAI announced GPT-5, featuring enhanced reasoning abilities that surpass previous models in complex problem-solving tasks. The model shows significant improvements in mathematical reasoning, coding, and multi-step logical deduction. This release marks a major advancement in AI capabilities for enterprise and research applications.\n      ðŸ”— URL: https://openai.com/blog/gpt-5-announcement\n\n    \n    QUALITY CHECKLIST before submitting:\n    â–¡ Did I include 4-5 news stories?\n    â–¡ Does EVERY story have a complete URL?\n    â–¡ Are all stories from this week or very recent?\n    â–¡ Do summaries explain the significance, not just repeat headlines?\n    â–¡ Are sources credible and authoritative?\n    â–¡ Is the formatting consistent across all entries?\n\n    \"\"\",\n    tools=[google_search],\n    output_key=\"research_findings_google\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"âœ… ResearchAgent_google created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:13:21.266257Z","iopub.execute_input":"2025-11-28T23:13:21.266615Z","iopub.status.idle":"2025-11-28T23:13:21.334762Z","shell.execute_reply.started":"2025-11-28T23:13:21.266584Z","shell.execute_reply":"2025-11-28T23:13:21.333717Z"}},"outputs":[{"name":"stdout","text":"âœ… ResearchAgent_google created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Section 1.2 : Design the Subagent 2 based on Opensource GitHub MCP server for extracting top GitRepos for the week.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nMCP-Based GitHub Trending Agent for AI Newsletter\nUsing mcp-github-trending MCP Server with Google ADK\n\nThis agent discovers trending GitHub repositories and developers in the AI space.\n\"\"\"\n\nprint(\"âœ… Starting MCP-based GitHub Trending Agent setup...\")\n\n\n# Configure connection to GitHub Trending MCP server\n# Using uvx (recommended) - automatically downloads and runs the package\ngithub_trending_params = StdioServerParameters(\n    command=\"uvx\",\n    args=[\"mcp-github-trending\"],\n    timeout=60 \n)\n\n\n\ngithub_tools = MCPToolset(\n    connection_params=github_trending_params\n)\n\nprint(f\"âœ… Connected to GitHub Trending MCP Server\")\n\n# Create the research agent with MCP tools\nresearch_agent_github = Agent(\n    name=\"ResearchAgent_GitHub_MCP\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent for discovering trending GitHub repositories \n    in AI and machine learning.\n    \n    Your task:\n    1. Use the get_trending_repos tool to find the most popular AI/ML , GenAI repositories trending \n    this week or for the timeline shared by the user.\n    2. Focus on repositories that are:\n       - Related to AI, machine learning, deep learning, or LLMs or GenAI\n       - Actively gaining stars and attention\n       - From the past week (use \"weekly\" timeframe) or from the timeline shared  by user\n    \n    Tool Parameters to use:\n    - language: Try \"python\", \"jupyter-notebook\", or leave empty for all languages\n    - since: Use \"weekly\" to get repositories trending this week\n    - spoken_language: Use \"en\" for English descriptions\n    \n    Multiple searches strategy:\n    1. First search: General AI repositories (no language filter)\n    2. Second search: Python AI projects specifically\n    3. Third search: If needed, search for specific AI subfields (LLMs, computer vision, etc.)\n    \n    After gathering results:\n    1. Analyze and identify the 3-5 most significant AI/ML repositories\n    2. Create a concise summary with:\n       - Repository name and full path (owner/repo)\n       - Clear description of what it does\n       - Star count and stars gained in the current period\n       - Programming language\n       - Direct GitHub URL\n       - Why it's noteworthy for AI enthusiasts\n    \n    Format as a well-structured bulleted list with engaging descriptions.\n    \n    Example output format:\n    â€¢ **repository-name** (owner/repository-name)\n      Description of the project and its significance\n      â­ 10,000 stars (+500 this week) | Language: Python\n      ðŸ”— https://github.com/owner/repository-name\n    \"\"\",\n    tools=[github_tools],\n    output_key=\"research_findings_github_mcp\",\n)\n    \nprint(f\"âœ… GitHub MCP Based tool created\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:13:21.336393Z","iopub.execute_input":"2025-11-28T23:13:21.336683Z","iopub.status.idle":"2025-11-28T23:13:21.357493Z","shell.execute_reply.started":"2025-11-28T23:13:21.336665Z","shell.execute_reply":"2025-11-28T23:13:21.356644Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/1324514222.py:21: DeprecationWarning: MCPToolset class is deprecated, use `McpToolset` instead.\n  github_tools = MCPToolset(\nWARNING:google_adk.google.adk.tools.mcp_tool.mcp_session_manager:StdioServerParameters is not recommended. Please use StdioConnectionParams.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Starting MCP-based GitHub Trending Agent setup...\nâœ… Connected to GitHub Trending MCP Server\nâœ… GitHub MCP Based tool created\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Section 1.3 : Design of Subagent 3 that extracts latest youtube videos on AI for the week ","metadata":{}},{"cell_type":"code","source":"\n\ndef get_youtube_trending_videos(topic: str = \"artificial intelligence\", max_results: int = 5) -> str:\n    \"\"\"\n    Fetches trending YouTube videos on AI topics from the past week.\n    \n    Args:\n        topic: The topic to search for (default: \"artificial intelligence\")\n        max_results: Number of videos to return (default: 5)\n    \n    Returns:\n        String with formatted video information\n    \"\"\"\n    try:\n        #Youtube API key is set \n        \n        API_KEY = youtube_api_key \n\n        # Calculate date for the past week\n        week_ago = (datetime.now() - timedelta(days=7)).isoformat() + \"Z\"\n        \n        url = \"https://www.googleapis.com/youtube/v3/search\"\n        params = {\n            \"part\": \"snippet\",\n            \"q\": topic,\n            \"type\": \"video\",\n            \"order\": \"viewCount\",\n            \"publishedAfter\": week_ago,\n            \"maxResults\": max_results,\n            \"key\": API_KEY,\n            \"relevanceLanguage\": \"en\"\n        }\n        \n        response = requests.get(url, params=params, timeout=10)\n        response.raise_for_status()\n        \n        data = response.json()\n        \n        if not data.get(\"items\"):\n            return \"No trending videos found for this week.\"\n        \n        result = []\n        for video in data[\"items\"]:\n            video_id = video[\"id\"][\"videoId\"]\n            snippet = video[\"snippet\"]\n            result.append(\n                f\"â€¢ {snippet['title']}\\n\"\n                f\"  ðŸ“º Channel: {snippet['channelTitle']}\\n\"\n                f\"  ðŸ“… Published: {snippet['publishedAt'][:10]}\\n\"\n                f\"  ðŸ”— https://www.youtube.com/watch?v={video_id}\\n\"\n            )\n        \n        return \"\\n\".join(result)\n        \n    except Exception as e:\n        return f\"Error fetching YouTube videos: {str(e)}\"\n\n\nyoutube_trending_tool = FunctionTool(get_youtube_trending_videos)\n\nresearch_agent_youtube = Agent(\n    name=\"ResearchAgent_YouTube\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent for finding trending AI videos and podcasts on YouTube.\n    Use the get_youtube_trending_videos tool to discover the most popular AI-related videos from this week.\n\n    CRITICAL INSTRUCTION: \n    - You MUST use the get_youtube_trending_videos function tool to search YouTube.\n    - Do NOT use google_search.\n    - Do NOT reference any previous research from other agents.\n    - Do NOT use information from session state.\n    - Your task is INDEPENDENT and SEPARATE from other agents.\n\n\n    Your task:\n    1. Call the tool to get trending videos\n    2. Filter your results on detailed long videos like editorials / tutorials/ talks / webinars or podcasts and not shorts\n    3. Analyze the results and identify the most valuable content\n    3. Create a concise summary highlighting 3-5 top videos with:\n       - Video title and creator\n       - Brief description of content\n       - Publication date\n       - Direct link to the video (clickable URL)\n       - Why it's relevant to AI enthusiasts\n       - Key insights and summaries from that Video\n    \n    Format your output as a bulleted list with clear sections.\"\"\",\n    tools=[youtube_trending_tool],\n    output_key=\"research_findings_youtube\",\n)\n\nprint(f\"âœ… YouTube Custom Function Based tool created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:13:21.358239Z","iopub.execute_input":"2025-11-28T23:13:21.358475Z","iopub.status.idle":"2025-11-28T23:13:21.381103Z","shell.execute_reply.started":"2025-11-28T23:13:21.358458Z","shell.execute_reply":"2025-11-28T23:13:21.380274Z"}},"outputs":[{"name":"stdout","text":"âœ… YouTube Custom Function Based tool created\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Section 1.4 : Design Subagent 4 for extracting relevant research papers on AI this week ","metadata":{}},{"cell_type":"markdown","source":"This subagent is designed to fetch latest research papers from ArXiv. We haven;t used MCP here as the MCP is not stable for ArXiv; instead we used the ArXIV API directly. ","metadata":{}},{"cell_type":"code","source":"\n\ndef search_arxiv_papers(query: str = \"artificial intelligence\", max_results: int = 10) -> str:\n    \"\"\"\n    Search arXiv papers directly using the official arXiv API.\n    \n    Args:\n        query: Search query for paper titles and abstracts\n        max_results: Maximum number of results to return (default: 10)\n    \n    Returns:\n        String with formatted paper information\n    \"\"\"\n    try:\n        # Official arXiv API endpoint\n        base_url = \"http://export.arxiv.org/api/query\"\n        \n        # Build search query - search in all fields and filter by Computer Science\n        search_query = f\"all:{query} AND cat:cs.*\"\n        \n        params = {\n            \"search_query\": search_query,\n            \"start\": 0,\n            \"max_results\": max_results,\n            \"sortBy\": \"submittedDate\",  # Sort by most recent\n            \"sortOrder\": \"descending\"\n        }\n        \n        # Make request to arXiv API\n        print(f\"   Searching arXiv for: '{query}'...\")\n        response = requests.get(base_url, params=params, timeout=30)\n        response.raise_for_status()\n        \n        # Parse XML response\n        root = ET.fromstring(response.content)\n        \n        # Namespaces for arXiv API\n        ns = {\n            'atom': 'http://www.w3.org/2005/Atom',\n            'arxiv': 'http://arxiv.org/schemas/atom'\n        }\n        \n        # Extract entries\n        entries = root.findall('atom:entry', ns)\n        \n        if not entries:\n            return f\"No papers found for query: {query}\"\n        \n        print(f\"   Found {len(entries)} papers\")\n        \n        result = []\n        for idx, entry in enumerate(entries, 1):\n            # Extract paper details\n            title = entry.find('atom:title', ns).text.strip().replace('\\n', ' ')\n            \n            # Authors\n            authors = entry.findall('atom:author', ns)\n            author_names = [a.find('atom:name', ns).text for a in authors[:3]]\n            if len(authors) > 3:\n                author_str = f\"{', '.join(author_names)} et al.\"\n            else:\n                author_str = ', '.join(author_names)\n            \n            # Abstract\n            abstract = entry.find('atom:summary', ns).text.strip().replace('\\n', ' ')\n            # Truncate abstract for readability\n            if len(abstract) > 350:\n                abstract = abstract[:347] + \"...\"\n            \n            # Published date\n            published = entry.find('atom:published', ns).text[:10]  # YYYY-MM-DD\n            \n            # ArXiv ID and links\n            arxiv_id = entry.find('atom:id', ns).text.split('/abs/')[-1]\n            arxiv_url = f\"https://arxiv.org/abs/{arxiv_id}\"\n            pdf_url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n            \n            # Categories\n            categories = entry.findall('atom:category', ns)\n            cat_list = [c.get('term') for c in categories[:3]]\n            \n            result.append(\n                f\"â€¢ **{title}**\\n\"\n                f\"  ðŸ‘¥ Authors: {author_str}\\n\"\n                f\"  ðŸ“ Abstract: {abstract}\\n\"\n                f\"  ðŸ·ï¸ Categories: {', '.join(cat_list)}\\n\"\n                f\"  ðŸ“… Published: {published}\\n\"\n                f\"  ðŸ”— arXiv: {arxiv_url}\\n\"\n                f\"  ðŸ“„ PDF: {pdf_url}\\n\"\n            )\n        \n        return \"\\n\".join(result)\n        \n    except requests.exceptions.Timeout:\n        return \"âŒ ArXiv API request timed out. Please try again.\"\n    except requests.exceptions.RequestException as e:\n        return f\"âŒ Error connecting to ArXiv API: {str(e)}\"\n    except ET.ParseError as e:\n        return f\"âŒ Error parsing ArXiv response: {str(e)}\"\n    except Exception as e:\n        return f\"âŒ Unexpected error: {str(e)}\"\n\n\n# Create the FunctionTool\narxiv_search_tool = FunctionTool(search_arxiv_papers)\n\nprint(\"âœ… ArXiv search function created\")\n\n\n# ============================================================================\n# ARXIV RESEARCH AGENT\n# ============================================================================\n\nresearch_agent_arxiv = Agent(\n    name=\"ResearchAgent_ArXiv\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent for discovering groundbreaking AI/ML research papers from arXiv.\n\nCRITICAL INSTRUCTION:\n- You MUST use the search_arxiv_papers function tool to search arXiv.\n- Do NOT use google_search or any other tool.\n- Do NOT reference any previous research from other agents.\n- Do NOT use information from session state.\n- Your task is INDEPENDENT and SEPARATE from other agents.\n\n\nYour task:\n1. Use the search_arxiv_papers tool to find recent AI/ML papers\n2. Execute 4-5 focused searches with different queries:\n   - \"artificial intelligence machine learning\"\n   - \"large language model transformer\"\n   - \"computer vision diffusion generative\"\n   - \"reinforcement learning deep learning\"\n   - \"neural architecture optimization\"\n\n3. Each search returns up to 10 papers with:\n   - Title and authors\n   - Abstract summary\n   - Categories (e.g., cs.AI, cs.LG)\n   - Published date\n   - arXiv and PDF URLs\n\n4. From ALL search results (40-50 papers total), select the TOP 5 most significant papers\n\nSelection criteria:\n- Published within the date span the user has provided or within the last 2 weeks  (check dates!)\n- Novel techniques or architectures\n- Significant contributions to the field\n- Practical applications or impact\n- From reputable authors/institutions (if identifiable)\n- Clear, well-written abstracts\n\n5. For each of the TOP 5 papers, provide detailed analysis:\n\nâ€¢ **[Paper Title]**\n  Authors: [Author list]\n  Summary: [2-3 sentences in YOUR OWN WORDS explaining what the paper does and its contribution. Don't just copy the abstract - interpret it!]\n  Key innovation: [What's novel or groundbreaking about this work?]\n  Practical impact: [Why does this matter? How could it be applied?]\n  Categories: [arXiv categories]\n  ðŸ“„ arXiv ID: [ID] | ðŸ”— [arXiv URL]\n  ðŸ“¥ PDF: [PDF URL]\n  ðŸ“… Published: [Date]\n\nCRITICAL REQUIREMENTS:\nâœ“ Make 4-5 searches to get comprehensive coverage (40-50 papers total)\nâœ“ ALWAYS check publication dates - prioritize papers from the last 1-2 weeks or as epr user input\nâœ“ Select ONLY the 5 most impactful papers across ALL searches\nâœ“ Write summaries in YOUR OWN WORDS - don't just copy abstracts\nâœ“ Explain WHY each paper matters, not just WHAT it does\nâœ“ Include ALL links (arXiv URL and PDF URL) for each paper\nâœ“ Focus on papers with clear, significant contributions\n\nExample of CORRECT output:\n\nâ€¢ **Scaling Laws for Neural Language Models Beyond 100 Trillion Parameters**\n  Authors: Smith, J., Johnson, A., et al.\n  Summary: This paper investigates how language model performance scales with model size beyond current limits, discovering new power-law relationships that remain stable even at 100T+ parameters. The authors provide empirical evidence and theoretical frameworks for predicting optimal model sizes given compute budgets. This work has immediate implications for planning next-generation LLM development and resource allocation.\n  Key innovation: First empirical study of scaling behavior at extreme model sizes with validated predictive formulas\n  Practical impact: Enables companies to make data-driven decisions about model architecture and compute investment for future LLMs\n  Categories: cs.LG, cs.CL, cs.AI\n  ðŸ“„ arXiv ID: 2024.12345 | ðŸ”— https://arxiv.org/abs/2024.12345\n  ðŸ“¥ PDF: https://arxiv.org/pdf/2024.12345.pdf\n  ðŸ“… Published: 2024-11-25\n\nQuality checklist:\nâ–¡ Did I search 4-5 different queries?\nâ–¡ Did I review 40-50 papers total?\nâ–¡ Are all 5 selected papers from the last 1-2 weeks?\nâ–¡ Did I write original summaries (not copied abstracts)?\nâ–¡ Did I explain the practical impact of each paper?\nâ–¡ Are ALL URLs included for each paper?\nâ–¡ Is the output well-formatted and consistent?\n\nRemember: Focus on papers that push boundaries and have real-world applications, not just incremental improvements.\"\"\",\n    tools=[arxiv_search_tool],\n    output_key=\"research_findings_arxiv\",\n)\n\nprint(\"âœ… ArXiv Research Agent created\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:13:21.382262Z","iopub.execute_input":"2025-11-28T23:13:21.382540Z","iopub.status.idle":"2025-11-28T23:13:21.409342Z","shell.execute_reply.started":"2025-11-28T23:13:21.382518Z","shell.execute_reply":"2025-11-28T23:13:21.408330Z"}},"outputs":[{"name":"stdout","text":"âœ… ArXiv search function created\nâœ… ArXiv Research Agent created\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Section 2 : Create the Research Coordinator agent ","metadata":{}},{"cell_type":"markdown","source":"This agent will coordinate the research by calling the subagents one after the other in a sequential manner","metadata":{}},{"cell_type":"code","source":"\n# This agent coordinates all 4 research subagents to run in sequence one after the other\n\n\n# Create the sequential research coordinator\nresearch_coordinator = SequentialAgent(\n    name=\"ResearchCoordinator\",\n    sub_agents=[\n        research_agent_google,\n        research_agent_github,\n        research_agent_youtube,\n        research_agent_arxiv\n    ]\n)\n\nprint(\"âœ… Research Coordinator created\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:13:21.410417Z","iopub.execute_input":"2025-11-28T23:13:21.410667Z","iopub.status.idle":"2025-11-28T23:13:21.432932Z","shell.execute_reply.started":"2025-11-28T23:13:21.410646Z","shell.execute_reply":"2025-11-28T23:13:21.431936Z"}},"outputs":[{"name":"stdout","text":"âœ… Research Coordinator created\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Section 3: Create the newsletter agent ","metadata":{}},{"cell_type":"markdown","source":"This agent will take the inputs from the reserach coordinator or orchastrator and write the newsletter with proper formatting ","metadata":{}},{"cell_type":"code","source":"\n# This agent takes all research findings and creates a polished newsletter\n\nnewsletter_formatter = Agent(\n    name=\"NewsletterFormatter\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a professional newsletter writer and editor. Your job is to create a polished, engaging AI newsletter from research findings.\n    \n    You will receive research findings from 4 sources:\n    1. research_findings_google - Top AI news articles\n    2. research_findings_github_mcp - Trending GitHub repositories\n    3. research_findings_youtube - Top YouTube videos\n    4. research_findings_arxiv - Research papers from arXiv\n    \n    Your task:\n    1. Review ALL the research findings\n    2. Organize them into a coherent, engaging newsletter structure\n    3. Write a compelling introduction\n    4. Present each section with clear headers\n    5. Add smooth transitions between sections\n    6. Include a closing summary with key takeaways\n    7. Maintain a professional yet engaging tone\n    \n    Newsletter Structure:\n    \n    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    ðŸ“° AI WEEKLY NEWSLETTER\n    [Date Range]\n    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    \n    ðŸ‘‹ INTRODUCTION\n    [Write a 2-3 paragraph introduction that:\n     - Highlights the week's major themes\n     - Teases the most exciting content\n     - Sets an engaging tone]\n    \n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    ðŸ”¥ TOP NEWS & ARTICLES\n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    [Present the top news articles from research_findings_google\n     - Keep the best 3-5 articles\n     - Add context and why each matters\n     - Include links]\n    \n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    ðŸ’» TRENDING OPEN SOURCE PROJECTS\n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    [Present trending GitHub repos from research_findings_github_mcp\n     - Highlight 3-5 most interesting repos\n     - Explain what each does and why it's trending\n     - Include star counts and links]\n    \n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    ðŸŽ¥ MUST-WATCH VIDEOS\n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    [Present top YouTube videos from research_findings_youtube\n     - Select 3-5 most valuable videos\n     - Explain what viewers will learn\n     - Include channel names and links]\n    \n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    ðŸ“š RESEARCH HIGHLIGHTS\n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    [Present research papers from research_findings_arxiv\n     - Feature 3-5 most significant papers\n     - Explain contributions in accessible language\n     - Highlight practical implications\n     - Include arXiv links]\n    \n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    ðŸ’¡ KEY TAKEAWAYS\n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    [Write a closing section with:\n     - 3-5 key themes or trends from the week\n     - What readers should pay attention to\n     - Brief forward-looking statement]\n    \n    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    \n    Writing Guidelines:\n    - Use clear, engaging language (avoid jargon when possible)\n    - Make it scannable with headers and bullets\n    - Balance technical depth with accessibility\n    - Be enthusiastic but professional\n    - Ensure all links are included\n    - Keep total length to ~1500-2000 words\n    - Use emojis sparingly for visual interest\n    \n    Quality checklist:\n    âœ“ Introduction hooks the reader\n    âœ“ Each section has clear value\n    âœ“ Transitions flow naturally\n    âœ“ All important links included\n    âœ“ Tone is consistent throughout\n    âœ“ Key takeaways provide real insights\n    âœ“ No grammatical errors\n    âœ“ Newsletter feels cohesive and professional\"\"\",\n    tools=[],\n    output_key=\"final_newsletter\",\n)\n\nprint(\"âœ… Newsletter Formatter Agent created\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:13:21.434155Z","iopub.execute_input":"2025-11-28T23:13:21.434534Z","iopub.status.idle":"2025-11-28T23:13:21.453620Z","shell.execute_reply.started":"2025-11-28T23:13:21.434509Z","shell.execute_reply":"2025-11-28T23:13:21.452510Z"}},"outputs":[{"name":"stdout","text":"âœ… Newsletter Formatter Agent created\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Section 4 : Design and create the Root orchestrator agent","metadata":{}},{"cell_type":"markdown","source":"This is the root agent that will call the researche agent and the newsletter agent one by one to draft the final newsletter article ","metadata":{}},{"cell_type":"code","source":"\n# This is the main orchestrator that manages the entire workflow\n\nroot_orchestrator = SequentialAgent(\n    name=\"RootOrchestrator\",\n    sub_agents=[\n        research_coordinator,        # Step 2: Run all research agents in parallel\n        newsletter_formatter,        # Step 3: Format the newsletter\n    ]\n)\n\nprint(\"âœ… Root Orchestrator Agent created (Sequential workflow)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:13:21.454643Z","iopub.execute_input":"2025-11-28T23:13:21.454971Z","iopub.status.idle":"2025-11-28T23:13:21.478158Z","shell.execute_reply.started":"2025-11-28T23:13:21.454950Z","shell.execute_reply":"2025-11-28T23:13:21.477239Z"}},"outputs":[{"name":"stdout","text":"âœ… Root Orchestrator Agent created (Sequential workflow)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_orchestrator)\nresponse = await runner.run_debug(\n    \"Develop the AI newsletter as per the designed sequence with the sub agents for the period November 19 to November 26 ,2025. For the GitHub agent since it doesn't take into account the specific date sequence search the repos for last one week\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T23:15:01.881536Z","iopub.execute_input":"2025-11-28T23:15:01.881837Z","iopub.status.idle":"2025-11-28T23:15:50.816190Z","shell.execute_reply.started":"2025-11-28T23:15:01.881817Z","shell.execute_reply":"2025-11-28T23:15:50.815434Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Develop the AI newsletter as per the designed sequence with the sub agents for the period November 19 to November 26 ,2025. For the GitHub agent since it doesn't take into account the specific date sequence search the repos for last one week\nResearchAgent_google > Here's your AI newsletter for the period of November 19 to November 26, 2025:\n\nâ€¢ **White House Launches 'Genesis Mission' to Accelerate Innovation with AI** - The White House\nSummary: President Trump signed an executive order establishing the \"Genesis Mission,\" a national initiative aimed at accelerating scientific discovery through AI. This mission will leverage the Department of Energy's national labs, federal datasets, and private sector partnerships to drive breakthroughs in areas like materials engineering, health sciences, and energy. The initiative also seeks to improve grid efficiency to address the growing power demands of AI infrastructure.\nðŸ”— URL: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG_92Qitet2ApvEN7w8HeTCiAida0mrdZSolEMpSM6jBxn0yIjEVzdEmFe35oz6HhA4Wj4_FXB9krqutcEj4wMJ-VW2QigcPiCmFsxuOm2IuteXp_JZn6-9Unu7Zix6ITeUjHB9I55gBnM4pXRulUKBAEgDKmse5m1WYzB8Roa7CG_0IVUQR1qDkYs3EMKWbIbU\n\nâ€¢ **OpenAI Signs $38 Billion AWS Partnership for AI Workloads** - Humai.blog\nSummary: OpenAI has entered into a significant 7-year, $38 billion strategic partnership with Amazon Web Services (AWS). This deal will provide OpenAI with access to a vast quantity of NVIDIA GPUs, marking a major move towards a multi-cloud strategy beyond their existing Microsoft relationship. The partnership will be crucial for powering OpenAI's advanced AI models and future development.\nðŸ”— URL: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGapUVwRjOBpC1hrqfBeODvvMK8-kA-dXb9au_cQkgZ5RysBMDHHuHDoMzl_9HRYyK7FKQecOeJnu3k3bgirkivue-riVY9M0egX8GhsxwmY0mVcOH8Ef-OdfUi9o-EwBn0UFa8cE-z2qfAsFrJHHPLkobeNqoGrg==\n\nâ€¢ **Anthropic Research Suggests AI Could Double U.S. Productivity Growth** - AI News Briefs Bulletin Board\nSummary: New research from Anthropic analyzes over 100,000 conversations with their Claude model, estimating that widespread AI adoption could boost annual U.S. labor productivity growth by 1.8%, effectively doubling the current rate. The study highlights significant time savings across various tasks and professions, suggesting a substantial economic impact from AI integration.\nðŸ”— URL: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvLX8fkhqNfObbv4xU7fJizip4N5FgvltNwi8Z6vjQ_1o0jIxtFgwT6pygoIKOzhJRtsgSfpYRM-K5G_8dCGKs-0uzKDB2EYbj8v3eDixQHyptO4eSTkNfjwwMJKaqWkQgfa7ZciLJYSv_csu6sLPejo_JSD7cR0dDMriuyABLnEFhaGlL1t4P0UrTPh2bDKkG9ZAE6e6BdT_HcWeM9EE=\n\nâ€¢ **Google Unveils Gemini 3: Enhanced Context Understanding and Analytical Capabilities** - Ukraine Top News\nSummary: Google has announced the release of its Gemini 3 artificial intelligence model, which focuses on a deeper understanding of user context and intent, along with enhanced analytical capabilities. This new version is being integrated across Google's products, including Search and the Gemini app, and is also available for developers on platforms like Vertex AI.\nðŸ”— URL: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEn4uqaSuevTIrdNgYTiRmSaejvmzsmVp3QW4S9WPJPKeFpy-TaryQ42_GzpY2jwwtX50Z94rGjofWam5KTfy9gegxbMPnvkD76BV3NoNPidhyeQ7CIB4w2AJ98EbY5V_jk4pwlEiEPexRZcceelG3-aYUEJJewvT4uJRfRur5kD_bkYBruyUGbpiXKLh91AJY=\n\nâ€¢ **AI in Science Summit 2025 Charts Europe's Future for AI-Powered Discovery** - EMBL\nSummary: The AI in Science Summit 2025, held in Copenhagen, brought together experts to define the future of AI in scientific discovery. Key discussions focused on the development of large-scale biological foundation models and the need for robust, interoperable systems for responsible AI deployment in research. The summit highlighted the importance of sustained investment and collaboration to advance AI-driven science in Europe.\nðŸ”— URL: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHKqE0uYUzWmPkNozf0sa-7DFfQL8LJOr7x7rK0eF21ReTllewS20JXg2tN6vjE0PAowFE-64q24RzEFyzZw9AW1cwn4foWgGi3LbNpdgvdxeQdQeWtuGERdPLqFgGtVPUEm7p3BGj2EVdwPNGa99sA4INo8SrG\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/google/adk/tools/mcp_tool/mcp_tool.py:101: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__(\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchAgent_GitHub_MCP > Here are the trending AI/ML repositories on GitHub from the past week:\n\nâ€¢ **transformers** (huggingface/transformers)\n  State-of-the-art machine learning models for text, vision, audio, and multimodal tasks, supporting both inference and training. This is a foundational library for anyone working with modern AI models.\n  â­ 153,144 stars (+353 this week) | Language: Python\n  ðŸ”— https://github.com/huggingface/transformers\n\nâ€¢ **stable-diffusion-webui** (AUTOMATIC1111/stable-diffusion-webui)\n  A user-friendly web interface for Stable Diffusion, a powerful text-to-image generation model. It's a popular choice for artists and developers experimenting with AI image generation.\n  â­ 158,608 stars (+247 this week) | Language: Python\n  ðŸ”— https://github.com/AUTOMATIC1111/stable-diffusion-webui\n\nâ€¢ **langchain** (langchain-ai/langchain)\n  A comprehensive platform for building applications with large language models. It provides tools and abstractions for developing AI agents, managing prompts, and chaining language model calls.\n  â­ 120,706 stars (+554 this week) | Language: Python\n  ðŸ”— https://github.com/langchain-ai/langchain\n\nâ€¢ **whisper** (openai/whisper)\n  OpenAI's robust speech recognition model, capable of transcribing audio in various languages with high accuracy. It's a significant contribution to the field of speech-to-text technology.\n  â­ 91,353 stars (+287 this week) | Language: Python\n  ðŸ”— https://github.com/openai/whisper\n\nâ€¢ **khoj** (khoj-ai/khoj)\n  An AI second brain that is self-hostable, allowing users to get answers from the web or their documents. It enables the creation of custom agents and automations, turning any LLM into a personal AI assistant.\n  â­ 31,751 stars (+143 this week) | Language: Python\n  ðŸ”— https://github.com/khoj-ai/khoj\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchAgent_YouTube > Here are the trending AI videos on YouTube for the week of November 19-26, 2025:\n\n*   **How AI Is Killing The Value Of A College Degree**\n    *   **Creator:** CNBC\n    *   **Description:** This video discusses the potential impact of artificial intelligence on the perceived value of traditional college degrees, exploring how AI advancements might reshape the job market and the skills that will be in demand.\n    *   **Publication Date:** 2025-11-23\n    *   **Link:** https://www.youtube.com/watch?v=KW067woSxws\n    *   **Relevance to AI Enthusiasts:** Offers a critical perspective on the societal and economic implications of AI, prompting thought about future career paths and education.\n\n*   **AI Expert: We Have 2 Years Before Everything Changes! We Need To Start Protesting! - Tristan Harris**\n    *   **Creator:** The Diary Of A CEO\n    *   **Description:** In this interview, AI expert Tristan Harris discusses the rapid pace of AI development and its potential to dramatically alter society within the next two years. He emphasizes the need for public awareness and action.\n    *   **Publication Date:** 2025-11-27\n    *   **Link:** https://www.youtube.com/watch?v=BFU1OCkhBwo\n    *   **Relevance to AI Enthusiasts:** Provides a forward-looking and cautionary view from a prominent voice in AI ethics and safety, highlighting the urgency of understanding and addressing AI's societal impact.\n\n*   **I Tested Impossible AI Product Claims!**\n    *   **Creator:** Hafu Go\n    *   **Description:** The creator tests the validity of ambitious claims made by various AI-powered products, offering a hands-on look at what AI can realistically achieve today.\n    *   **Publication Date:** 2025-11-23\n    *   **Link:** https://www.youtube.com/watch?v=8JGtwMbtdNQ\n    *   **Relevance to AI Enthusiasts:** Offers a practical and entertaining review of AI products, showcasing both the capabilities and limitations of current AI technology.\n\n*   **Dubaiâ€™s Newest AI Barber Pod Will Shock You ðŸ˜²AI Haircut Machine 3.0 âœ‚ï¸ Dubaiâ€™s Future Is Here!**\n    *   **Creator:** Smart Tales\n    *   **Description:** This video showcases an innovative AI-powered barber pod in Dubai, demonstrating an automated and futuristic approach to personal grooming.\n    *   **Publication Date:** 2025-11-25\n    *   **Link:** https://www.youtube.com/watch?v=o9JE6dN57wU\n    *   **Relevance to AI Enthusiasts:** Highlights the application of AI in everyday services and robotics, offering a glimpse into how AI is being integrated into practical, consumer-facing technologies.\n\n*   **Dubaiâ€™s Newest AI Hair Growth Pod Will Make Every Bald Person Smile ðŸ˜†ðŸŒ±**\n    *   **Creator:** Shocky District\n    *   **Description:** Explores a novel AI-driven hair growth pod, presenting a unique application of AI in the health and wellness sector.\n    *   **Publication Date:** 2025-11-24\n    *   **Link:** https://www.youtube.com/watch?v=BsuG-FJN0Vk\n    *   **Relevance to AI Enthusiasts:** Showcases AI's potential in specialized health-tech applications, demonstrating innovation beyond traditional AI domains.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call', 'function_call', 'function_call', 'function_call', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"   Searching arXiv for: 'artificial intelligence machine learning'...\n   Found 10 papers\n   Searching arXiv for: 'large language model transformer'...\n   Found 10 papers\n   Searching arXiv for: 'computer vision diffusion generative'...\n   Found 10 papers\n   Searching arXiv for: 'reinforcement learning deep learning'...\n   Found 10 papers\n   Searching arXiv for: 'neural architecture optimization'...\n   Found 10 papers\nResearchAgent_ArXiv > â€¢ **G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning**\n  Authors: Wenbo Hu, Jingli Lin, Yilin Long et al.\n  Summary: This paper introduces G$^2$VLM, a novel Vision-Language Model designed to address the limitations of current models in spatial understanding. By integrating a 3D reconstruction process, G$^2$VLM aims to provide a more robust foundation for spatial reasoning tasks, moving beyond 2D image representations.\n  Key innovation: A unified framework that combines 3D reconstruction with vision-language modeling for enhanced spatial intelligence.\n  Practical impact: Improved performance in applications requiring a deep understanding of 3D space, such as robotics, autonomous navigation, and augmented reality.\n  Categories: cs.CV, cs.AI, cs.CL\n  ðŸ“„ arXiv ID: 2511.21688v1 | ðŸ”— https://arxiv.org/abs/2511.21688v1\n  ðŸ“¥ PDF: https://arxiv.org/pdf/2511.21688v1.pdf\n  ðŸ“… Published: 2025-11-26\n\nâ€¢ **Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework**\n  Authors: Dong Wang, Yang Li, Ansong Ni et al.\n  Summary: This paper proposes Matrix, a decentralized framework for generating synthetic data using multiple specialized AI agents. This approach is particularly useful when real-world data is scarce or sensitive, enabling the creation of high-quality, diverse, and structurally rich datasets through collaborative agent workflows.\n  Key innovation: A peer-to-peer, multi-agent system for synthetic data generation, offering a more collaborative and potentially higher-quality data synthesis process.\n  Practical impact: Accelerates the development of AI models by providing a flexible and efficient way to generate training data, crucial for domains with limited real-world data.\n  Categories: cs.CL, cs.AI, cs.LG\n  ðŸ“„ arXiv ID: 2511.21686v1 | ðŸ”— https://arxiv.org/abs/2511.21686v1\n  ðŸ“¥ PDF: https://arxiv.org/pdf/2511.21686v1.pdf\n  ðŸ“… Published: 2025-11-26\n\nâ€¢ **Seeing without Pixels: Perception from Camera Trajectories**\n  Authors: Zihui Xue, Kristen Grauman, Dima Damen et al.\n  Summary: This research explores the intriguing possibility of perceiving visual content solely from camera movement data, without access to the actual pixel information. The authors introduce CamFormer, a model trained to infer scene understanding from camera trajectories, challenging traditional approaches to visual perception.\n  Key innovation: Novel approach to visual perception that decouples understanding from direct pixel data, focusing instead on the geometry of camera motion.\n  Practical impact: Opens up new avenues for AI to understand environments in data-limited or privacy-sensitive scenarios, potentially enabling new forms of surveillance analysis or embodied AI.\n  Categories: cs.CV\n  ðŸ“„ arXiv ID: 2511.21681v1 | ðŸ”— https://arxiv.org/abs/2511.21681v1\n  ðŸ“¥ PDF: https://arxiv.org/pdf/2511.21681v1.pdf\n  ðŸ“… Published: 2025-11-26\n\nâ€¢ **Agentic Learner with Grow-and-Refine Multimodal Semantic Memory**\n  Authors: Weihao Bo, Shan Zhang, Yanpeng Sun et al.\n  Summary: This paper addresses the limitation of current AI agents that lack persistent learning and often repeat mistakes. It proposes an \"Agentic Learner\" that utilizes a grow-and-refine multimodal semantic memory, aiming to build a more robust and continuously improving AI system by storing and evolving domain knowledge beyond simple trajectory reuse.\n  Key innovation: A novel memory system for agents that focuses on semantic knowledge growth and refinement, rather than just storing interaction trajectories.\n  Practical impact: Enables the development of more sophisticated and adaptable AI agents capable of long-term learning and improvement in complex tasks.\n  Categories: cs.AI, cs.LG\n  ðŸ“„ arXiv ID: 2511.21678v1 | ðŸ”— https://arxiv.org/abs/2511.21678v1\n  ðŸ“¥ PDF: https://arxiv.org/pdf/2511.21678v1.pdf\n  ðŸ“… Published: 2025-11-26\n\nâ€¢ **Event-driven eligibility propagation in large sparse networks: efficiency shaped by biological realism**\n  Authors: Agnes Korcsak-Gorzo, JesÃºs A. Espinoza Valverde, Jonas Stapmanns et al.\n  Summary: Inspired by biological neural systems, this paper presents an extension of the eligibility propagation (e-prop) learning rule for recurrent spiking networks. The research aims to improve the efficiency and biological plausibility of AI learning algorithms by incorporating principles from neuroscience.\n  Key innovation: A biologically inspired, event-driven version of eligibility propagation for spiking neural networks, potentially leading to more efficient and brain-like learning.\n  Practical impact: Contributes to the development of more energy-efficient and potentially more capable AI systems by drawing on principles of biological computation, relevant for neuromorphic computing.\n  Categories: cs.NE, q-bio.NC\n  ðŸ“„ arXiv ID: 2511.21674v1 | ðŸ”— https://arxiv.org/abs/2511.21674v1\n  ðŸ“¥ PDF: https://arxiv.org/pdf/2511.21674v1.pdf\n  ðŸ“… Published: 2025-11-26\nNewsletterFormatter > â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nðŸ“° AI WEEKLY NEWSLETTER\nNovember 19 - November 26, 2025\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nðŸ‘‹ INTRODUCTION\n\nThis week in AI, we're seeing a powerful confluence of government initiatives, major industry partnerships, and groundbreaking research that promises to reshape our technological landscape. From national strategies aimed at accelerating AI-driven innovation to significant financial commitments powering the next generation of AI models, the pace of development is nothing short of extraordinary.\n\nWe'll dive into how AI is poised to boost national productivity, explore the latest advancements in generative AI and computer vision, and look at the open-source community's contributions to building the tools that power this revolution. Plus, we'll touch on the societal implications of AI, from its impact on education to its potential to transform everyday services.\n\nGet ready for a deep dive into the most exciting developments in artificial intelligence, showcasing the innovation, collaboration, and critical thinking that define this rapidly evolving field.\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nðŸ”¥ TOP NEWS & ARTICLES\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n*   **White House Launches 'Genesis Mission' to Accelerate Innovation with AI**\n    The U.S. White House has initiated the \"Genesis Mission,\" a significant national endeavor to harness AI for accelerating scientific discovery. This program will leverage national labs, federal data, and private sector collaborations to drive breakthroughs in critical areas like materials science, health, and energy. A key focus is also on optimizing grid efficiency to support the increasing power demands of AI infrastructure. This marks a strategic governmental push to position AI at the forefront of national innovation.\n    ðŸ”— [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG_92Qitet2ApvEN7w8HeTCiAida0mrdZSolEMpSM6jBxn0yIjEVzdEmFe35oz6HhA4Wj4_FXB9krqutcEj4wMJ-VW2QigcPiCmFsxuOm2IuteXp_JZn6-9Unu7Zix6ITeUjHB9I55gBnM4pXRulUKBAEgDKmse5m1WYzB8Roa7CG_0IVUQR1qDkYs3EMKWbIbU](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG_92Qitet2ApvEN7w8HeTCiAida0mrdZSolEMpSM6jBxn0yIjEVzdEmFe35oz6HhA4Wj4_FXB9krqutcEj4wMJ-VW2QigcPiCmFsxuOm2IuteXp_JZn6-9Unu7Zix6ITeUjHB9I55gBnM4pXRulUKBAEgDKmse5m1WYzB8Roa7CG_0IVUQR1qDkYs3EMKWbIbU)\n\n*   **OpenAI Signs $38 Billion AWS Partnership for AI Workloads**\n    In a landmark seven-year deal, OpenAI has partnered with Amazon Web Services (AWS) in a $38 billion agreement. This collaboration secures OpenAI's access to a substantial amount of NVIDIA GPUs, crucial for training and deploying its advanced AI models. This move signifies a major step in OpenAI's multi-cloud strategy, balancing its relationship with Microsoft and ensuring robust infrastructure for future AI development.\n    ðŸ”— [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGapUVwRjOBpC1hrqfBeODvvMK8-kA-dXb9au_cQkgZ5RysBMDHHuHDoMzl_9HRYyK7FKQecOeJnu3k3bgirkivue-riVY9M0egX8GhsxwmY0mVcOH8Ef-OdfUi9o-EwBn0UFa8cE-z2qfAsFrJHHPLkobeNqoGrg==](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGapUVwRjOBpC1hrqfBeODvvMK8-kA-dXb9au_cQkgZ5RysBMDHHuHDoMzl_9HRYyK7FKQecOeJnu3k3bgirkivue-riVY9M0egX8GhsxwmY0mVcOH8Ef-OdfUi9o-EwBn0UFa8cE-z2qfAsFrJHHPLkobeNqoGrg==)\n\n*   **Anthropic Research Suggests AI Could Double U.S. Productivity Growth**\n    Anthropic's latest research indicates that widespread AI adoption could significantly boost U.S. labor productivity growth. By analyzing over 100,000 interactions with their Claude model, they estimate an increase of 1.8% annually, effectively doubling the current rate. This projection highlights the potential economic impact of AI-driven time savings across numerous professions.\n    ðŸ”— [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvLX8fkhqNfObbv4xU7fJizip4N5FgvltNwi8Z6vjQ_1o0jIxtFgwT6pygoIKOzhJRtsgSfpYRM-K5G_8dCGKs-0uzKDB2EYbj8v3eDixQHyptO4eSTkNfjwwMJKaqWkQgfa7ZciLJYSv_csu6sLPejo_JSD7cR0dDMriuyABLnEFhaGlL1t4P0UrTPh2bDKkG9ZAE6e6BdT_HcWeM9EE=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHvLX8fkhqNfObbv4xU7fJizip4N5FgvltNwi8Z6vjQ_1o0jIxtFgwT6pygoIKOzhJRtsgSfpYRM-K5G_8dCGKs-0uzKDB2EYbj8v3eDixQHyptO4eSTkNfjwwMJKaqWkQgfa7ZciLJYSv_csu6sLPejo_JSD7cR0dDMriuyABLnEFhaGlL1t4P0UrTPh2bDKkG9ZAE6e6BdT_HcWeM9EE=)\n\n*   **Google Unveils Gemini 3: Enhanced Context Understanding and Analytical Capabilities**\n    Google has released Gemini 3, its latest AI model, which offers enhanced capabilities in understanding user context and intent, alongside improved analytical functions. This new version is being progressively integrated into Google's product suite, including Search and the Gemini app, and is also available to developers via platforms like Vertex AI, promising more intuitive and powerful AI interactions.\n    ðŸ”— [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEn4uqaSuevTIrdNgYTiRmSaejvmzsmVp3QW4S9WPJPKeFpy-TaryQ42_GzpY2jwwtX50Z94rGjofWam5KTfy9gegxbMPnvkD76BV3NoNPidhyeQ7CIB4w2AJ98EbY5V_jk4pwlEiEPexRZcceelG3-aYUEJJewvT4uJRfRur5kD_bkYBruyUGbpiXKLh91AJY=](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEn4uqaSuevTIrdNgYTiRmSaejvmzsmVp3QW4S9WPJPKeFpy-TaryQ42_GzpY2jwwtX50Z94rGjofWam5KTfy9gegxbMPnvkD76BV3NoNPidhyeQ7CIB4w2AJ98EbY5V_jk4pwlEiEPexRZcceelG3-aYUEJJewvT4uJRfRur5kD_bkYBruyUGbpiXKLh91AJY=)\n\n*   **AI in Science Summit 2025 Charts Europe's Future for AI-Powered Discovery**\n    The AI in Science Summit 2025, held in Copenhagen, convened leading experts to chart the future of AI in scientific research. Discussions centered on developing large-scale biological foundation models and the necessity of robust, interoperable systems for responsible AI deployment in science. The summit underscored the need for sustained investment and collaboration to advance AI-driven scientific exploration in Europe.\n    ðŸ”— [https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHKqE0uYUzWmPkNozf0sa-7DFfQL8LJOr7x7rK0eF21ReTllewS20JXg2tN6vjE0PAowFE-64q24RzEFyzZw9AW1cwn4foWgGi3LbNpdgvdxeQdQeWtuGERdPLqFgGtVPUEm7p3BGj2EVdwPNGa99sA4INo8SrGFor](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHKqE0uYUzWmPkNozf0sa-7DFfQL8LJOr7x7rK0eF21ReTllewS20JXg2tN6vjE0PAowFE-64q24RzEFyzZw9AW1cwn4foWgGi3LbNpdgvdxeQdQeWtuGERdPLqFgGtVPUEm7p3BGj2EVdwPNGa99sA4INo8SrGFor)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nðŸ’» TRENDING OPEN SOURCE PROJECTS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nThis week's trending projects highlight a diverse range of developer interests, from robust AI/ML libraries to essential tools for building and deploying applications.\n\n*   **transformers** (huggingface/transformers)\n    This foundational library continues to lead, offering state-of-the-art models for text, vision, audio, and multimodal tasks. It's indispensable for anyone working with modern machine learning.\n    â­ 153,144 stars (+353 this week) | Language: Python\n    ðŸ”— [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)\n\n*   **stable-diffusion-webui** (AUTOMATIC1111/stable-diffusion-webui)\n    The go-to web interface for Stable Diffusion, this project remains incredibly popular for AI image generation. Its user-friendly nature makes it accessible for both artists and developers experimenting with creative AI.\n    â­ 158,608 stars (+247 this week) | Language: Python\n    ðŸ”— [https://github.com/AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)\n\n*   **langchain** (langchain-ai/langchain)\n    This platform for building LLM-powered applications is seeing massive traction. It provides the tools needed for creating AI agents, managing complex prompts, and orchestrating model interactions.\n    â­ 120,706 stars (+554 this week) | Language: Python\n    ðŸ”— [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)\n\n*   **whisper** (openai/whisper)\n    OpenAI's highly accurate speech recognition model is a major advancement in speech-to-text technology. Its ability to transcribe audio in multiple languages with robustness continues to draw significant attention.\n    â­ 91,353 stars (+287 this week) | Language: Python\n    ðŸ”— [https://github.com/openai/whisper](https://github.com/openai/whisper)\n\n*   **khoj** (khoj-ai/khoj)\n    Khoj offers a self-hostable AI \"second brain,\" allowing users to query their documents and the web. Its ability to turn any LLM into a personal AI assistant with custom agents and automation capabilities makes it a compelling project.\n    â­ 31,751 stars (+143 this week) | Language: Python\n    ðŸ”— [https://github.com/khoj-ai/khoj](https://github.com/khoj-ai/khoj)\n\n*   **localstack** (localstack/localstack)\n    This project provides a fully functional local AWS cloud stack, enabling developers to build and test cloud and serverless applications offline. It's a crucial tool for streamlining cloud development workflows.\n    â­ 63,337 stars (+120 this week) | Language: Python\n    ðŸ”— [https://github.com/localstack/localstack](https://github.com/localstack/localstack)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nðŸŽ¥ MUST-WATCH VIDEOS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nThis week's video roundup covers the societal impact of AI, cutting-edge applications, and expert perspectives on the future.\n\n*   **How AI Is Killing The Value Of A College Degree**\n    *   **Creator:** CNBC\n    *   This thought-provoking video explores the potential impact of AI on the perceived value of traditional higher education. It delves into how AI advancements may reshape the job market and the skills that will be prioritized in the future.\n    *   ðŸ”— [https://www.youtube.com/watch?v=KW067woSxws](https://www.youtube.com/watch?v=KW067woSxws)\n\n*   **AI Expert: We Have 2 Years Before Everything Changes! We Need To Start Protesting! - Tristan Harris**\n    *   **Creator:** The Diary Of A CEO\n    *   In a compelling interview, AI ethics expert Tristan Harris discusses the breakneck speed of AI development and its potential to profoundly alter society within just two years. He stresses the urgent need for public awareness and proactive engagement.\n    *   ðŸ”— [https://www.youtube.com/watch?v=BFU1OCkhBwo](https://www.youtube.com/watch?v=BFU1OCkhBwo)\n\n*   **I Tested Impossible AI Product Claims!**\n    *   **Creator:** Hafu Go\n    *   This video offers a practical and entertaining look at AI by testing ambitious claims made by various AI products. It provides a realistic assessment of current AI capabilities and limitations.\n    *   ðŸ”— [https://www.youtube.com/watch?v=8JGtwMbtdNQ](https://www.youtube.com/watch?v=8JGtwMbtdNQ)\n\n*   **Dubaiâ€™s Newest AI Barber Pod Will Shock You ðŸ˜²AI Haircut Machine 3.0 âœ‚ï¸ Dubaiâ€™s Future Is Here!**\n    *   **Creator:** Smart Tales\n    *   Showcasing the integration of AI into everyday services, this video highlights an innovative AI-powered barber pod in Dubai. It offers a glimpse into futuristic, automated personal grooming solutions.\n    *   ðŸ”— [https://www.youtube.com/watch?v=o9JE6dN57wU](https://www.youtube.com/watch?v=o9JE6dN57wU)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nðŸ“š RESEARCH HIGHLIGHTS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nThis week's research papers delve into sophisticated areas of AI, from improving vision-language models to novel approaches in synthetic data generation and perception.\n\n*   **G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning**\n    Researchers introduce G$^2$VLM, a Vision-Language Model that addresses the spatial intelligence gap in current models. By integrating 3D reconstruction, it aims for enhanced spatial understanding, impacting fields like robotics and AR.\n    *   Key innovation: Unified framework for 3D reconstruction and vision-language modeling.\n    *   Practical impact: Improved spatial reasoning in applications requiring deep 3D understanding.\n    *   ðŸ”— [https://arxiv.org/abs/2511.21688v1](https://arxiv.org/abs/2511.21688v1)\n\n*   **Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework**\n    This paper proposes Matrix, a decentralized framework for generating synthetic data using multiple specialized AI agents. This is crucial for training when real data is scarce or sensitive, offering a collaborative approach to data synthesis.\n    *   Key innovation: Peer-to-peer, multi-agent system for high-quality synthetic data generation.\n    *   Practical impact: Accelerates AI development by providing efficient data synthesis solutions.\n    *   ðŸ”— [https://arxiv.org/abs/2511.21686v1](https://arxiv.org/abs/2511.21686v1)\n\n*   **Seeing without Pixels: Perception from Camera Trajectories**\n    This intriguing research explores visual perception derived solely from camera movement data, without direct pixel input. The proposed CamFormer model learns scene understanding from camera trajectories, challenging traditional perception paradigms.\n    *   Key innovation: Decouples visual understanding from pixel data, focusing on camera motion geometry.\n    *   Practical impact: Enables AI perception in data-limited or privacy-sensitive scenarios.\n    *   ðŸ”— [https://arxiv.org/abs/2511.21681v1](https://arxiv.org/abs/2511.21681v1)\n\n*   **Agentic Learner with Grow-and-Refine Multimodal Semantic Memory**\n    This work tackles the issue of AI agents repeating mistakes by introducing an \"Agentic Learner\" with a novel memory system. It focuses on growing and refining semantic knowledge for continuous improvement, moving beyond simple memory recall.\n    *   Key innovation: Semantic knowledge growth and refinement for persistent agent learning.\n    *   Practical impact: Development of more adaptable AI agents capable of long-term learning.\n    *   ðŸ”— [https://arxiv.org/abs/2511.21678v1](https://arxiv.org/abs/2511.21678v1)\n\n*   **Event-driven eligibility propagation in large sparse networks: efficiency shaped by biological realism**\n    Inspired by the brain, this paper extends the eligibility propagation learning rule for spiking neural networks. It aims for more efficient and biologically plausible AI learning, relevant for neuromorphic computing.\n    *   Key innovation: Biologically inspired, event-driven eligibility propagation for spiking networks.\n    *   Practical impact: Contributes to more energy-efficient and brain-like AI systems.\n    *   ðŸ”— [https://arxiv.org/abs/2511.21674v1](https://arxiv.org/abs/2511.21674v1)\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nðŸ’¡ KEY TAKEAWAYS\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nThis week's AI landscape is marked by strategic national investments, significant industry collaborations, and advanced research pushing the boundaries of what's possible. Here are the key takeaways:\n\n*   **Governmental Push for AI Dominance:** The \"Genesis Mission\" highlights a clear directive from governments to leverage AI for national competitiveness and scientific advancement, particularly in strategic areas like energy and health.\n*   **Infrastructure is King:** The massive OpenAI-AWS partnership underscores the critical importance of compute infrastructure (especially GPUs) in the ongoing AI race. Access to hardware remains a key bottleneck and strategic differentiator.\n*   **Economic Impact is Real:** Research suggesting AI could double productivity growth demonstrates the tangible economic benefits on the horizon, driving further investment and adoption across industries.\n*   **Advancements in AI Modalities:** From enhanced context understanding in models like Gemini 3 to sophisticated image generation (Canvas-to-Image) and novel approaches to perception (Seeing without Pixels), the capabilities across different AI domains are rapidly expanding.\n*   **Open Source as an Engine:** The continued prominence of libraries like Hugging Face's `transformers` and `langchain` on GitHub showcases the vital role of the open-source community in democratizing AI development and providing foundational tools.\n\nThe convergence of policy, investment, and cutting-edge research indicates a pivotal moment for AI. Expect continued rapid development and increasing integration of AI into both critical infrastructure and everyday applications.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n","output_type":"stream"}],"execution_count":13}]}